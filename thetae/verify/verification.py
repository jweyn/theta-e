#
# Copyright (c) 2017 Jonathan Weyn <jweyn@uw.edu>
#
# See the file LICENSE for your rights.
#

'''
Retrieve verification from MesoWest and CF6 files.
'''

from MesoPy import Meso
import pandas as pd
import numpy as np
from thetae.util import _meso_api_dates, _date_to_string, Daily
from datetime import datetime, timedelta

def _cf6_wind(config, stid):
    '''
    After code by Luke Madaus
    
    This function is used internally only.
    
    Generates wind verification values from climate CF6 files stored in
    site_directory. These files can be generated by _get_cf6_files.
    '''
    
    site_directory = '%s/archive' % config['THETAE_ROOT']
    if int(config['debug']) > 0:
        print('verification: searching for CF6 files in %s' % site_directory)
    allfiles = os.listdir(site_directory)
    filelist = [f for f in allfiles if f.startswith(stid.upper()) and
                f.endswith('.cli')]
    filelist.sort()
    if len(filelist) == 0:
        raise IOError('No CF6 files found in %s for site %s.' % (site_directory,
                                                                 stid))
    if int(config['debug']) > 50:
        print('verification: found %d CF6 files' % len(filelist))
    
    # Interpret CF6 files
    if int(config['debug']) > 50:
        print('verification: reading CF6 files')
    cf6_values = {}
    for file in filelist:
        year,month = re.search('(\d{4})(\d{2})', file).groups()
        infile = open('%s/%s' % (site_directory, file), 'r')
        for line in infile:
            matcher = re.compile('( \d{1}|\d{2}) ( \d{2}|-\d{2}|  \d{1}| -\d{1}|\d{3})')
            if matcher.match(line):
                # We've found an ob line!
                lsp = line.split()
                day = int(lsp[0])
                curdt = datetime(int(year), int(month), day)
                cf6_values[curdt] = {}
                # Wind
                if lsp[11] == 'M':
                    cf6_values[curdt]['wind'] = 0.0
                else:
                    cf6_values[curdt]['wind'] = float(lsp[11])*0.868976

    return cf6_values

def _climo_wind(config, dates=None):
    '''
    This function is used internally only.
    
    Fetches climatological wind data using ulmo package to retrieve NCDC
    archives.
    '''
    
    import ulmo
    climo_station_id = config['Stations'][stid]['climo_id']
    
    if int(config['debug']) > 0:
        print('verification: fetching wind data from NCDC (may take a while)')
    v = 'WSF2'
    D = ulmo.ncdc.ghcn_daily.get_data(climo_station_id, as_dataframe=True,
                                      elements=[v])
    wind_dict = {}
    if dates is None:
        dates = list(D[v].index.to_timestamp().to_pydatetime())
    for date in dates:
        wind_dict[date] = {'wind' : D[v].loc[date]['value']/10.*1.94384}

    return wind_dict

def get_verification(config, stid, start, end):
    '''
    Generates verification data from MesoWest API. Also reads CF6 files to
    check max wind data.
    '''

    # MesoWest token and init
    meso_token = config['Verify']['api_key']
    m = Meso(token=meso_token)
    if int(config['debug']) > 9:
        print('verification: MesoPy initialized for station %s' % stid)
    
    # Look for desired variables
    vars_request = ['air_temp', 'wind_speed', 'precip_accum_one_hour']
    vars_option  = ['air_temp_low_6_hour', 'air_temp_high_6_hour',
                    'precip_accum_six_hour']
    
    # Add variables to the api request if they exist
    if int(config['debug']) > 50:
        print('verification: searching for 6-hourly variables...')
    latest = m.latest(stid=stid)
    obs_list = list(latest['STATION'][0]['SENSOR_VARIABLES'].keys())
    for var in vars_option:
        if var in obs_list:
            if int(config['debug']) > 9:
                print('verification: using variable %s' % var)
            vars_request += [var]
    vars_api = ''
    for var in vars_request:
        vars_api += var + ','
    vars_api = vars_api[:-1]

    # Units
    units = 'temp|f,precip|in,speed|kts'

    # Retrieve data
    print('verification: retrieving data from %s to %s...' % (start, end))
    obs = m.timeseries(stid=stid, start=start, end=end, vars=vars_api,
                       units=units)
    obspd = pd.DataFrame.from_dict(obs['STATION'][0]['OBSERVATIONS'])

    # Rename columns to requested vars. This changes the columns in the
    # DataFrame to corresponding names in vars_request, because otherwise the
    # columns returned by MesoPy are weird.
    obs_var_names = obs['STATION'][0]['SENSOR_VARIABLES']
    obs_var_keys  = list(obs_var_names.keys())
    col_names = list(map(''.join, obspd.columns.values))
    for c in range(len(col_names)):
        col = col_names[c]
        for k in range(len(obs_var_keys)):
            key = obs_var_keys[k]
            if col == list(obs_var_names[key].keys())[0]:
                col_names[c] = key
    obspd.columns = col_names

    # Let's add a check here to make sure that we do indeed have all of the
    # variables we want
    for var in vars_request:
        if var not in col_names:
            obspd[var] = np.nan

    # Change datetime column to datetime object, subtract 6 hours to use 6Z days
    dateobj = pd.to_datetime(obspd['date_time']) - timedelta(hours=6)
    obspd['date_time'] = dateobj
    datename = 'DATETIME'
    obspd = obspd.rename(columns={'date_time' : datename})

    # Now we're going to group the data into daily values. First, we group by
    # hour to be sure we have the right precipitation accumulations, which are
    # officially recorded by hour.

    def hour(dates):
        date = dates.iloc[0]
        return datetime(date.year, date.month, date.day, date.hour)
    
    def last(values):
        return values.iloc[-1]

    # Define an aggregation function for pandas groupby
    aggregate = {datename : hour}
    if 'air_temp_high_6_hour' in vars_request and 'air_temp_low_6_hour' in vars_request:
        aggregate['air_temp_high_6_hour'] = np.max
        aggregate['air_temp_low_6_hour'] = np.min
    aggregate['air_temp'] = {'air_temp_max' : np.max, 'air_temp_min' : np.min}
    if 'precip_accum_six_hour' in vars_request:
        aggregate['precip_accum_six_hour'] = np.max
    aggregate['wind_speed'] = np.max
    aggregate['precip_accum_one_hour'] = np.max

    if int(config['debug']) > 50:
        print('verification: grouping data by hour')
    obs_hourly = obspd.groupby([pd.DatetimeIndex(obspd[datename]).year,
                                pd.DatetimeIndex(obspd[datename]).month,
                                pd.DatetimeIndex(obspd[datename]).day,
                                pd.DatetimeIndex(obspd[datename]).hour]).agg(aggregate)

    # Rename columns
    col_names = obs_hourly.columns.values
    col_names_new = []
    for c in range(len(col_names)):
        if col_names[c][0] == 'air_temp':
            col_names_new.append(col_names[c][1])
        else:
            col_names_new.append(col_names[c][0])
    obs_hourly.columns = col_names_new

    # Now group by day. Note that we changed the time to subtract 6 hours, so
    # days are nicely defined as 6Z to 6Z.

    def day(dates):
        date = dates.iloc[0]
        return datetime(date.year, date.month, date.day)

    aggregate[datename] = day
    aggregate['air_temp_min'] = np.min
    aggregate['air_temp_max'] = np.max
    aggregate['precip_accum_six_hour'] = np.sum
    try:
        aggregate.pop('air_temp')
    except:
        pass

    if int(config['debug']) > 50:
        print('verification: grouping data by day')
    obs_daily = obs_hourly.groupby([pd.DatetimeIndex(obs_hourly[datename]).year,
                    pd.DatetimeIndex(obs_hourly[datename]).month,
                    pd.DatetimeIndex(obs_hourly[datename]).day]).agg(aggregate)

    # Now we check for wind values from the CF6 files, which are the actual
    # verification

    if int(config['debug']) > 10:
        print('verification: checking matching dates for daily obs and CF6')
    try:
        climo_values = _climo_wind(dates)
    except:
        print('verification warning: problem reading climo data')
        climo_values = {}
    try:
        cf6_values = _cf6_wind()
    except:
        print('verification warning: no CF6 files found')
        cf6_values = {}
    climo_values.update(cf6_values) # CF6 overrides
    count_rows = 0
    for row in obs_daily.iterrows():
        date = row[1][datename]
        if date in climo_values.keys():
            count_rows += 1
            obs_wind = row[1]['wind_speed']
            cf6_wind = climo_values[date]['wind']
            obs_daily.loc[[row[0]],'wind_speed'] = max(obs_wind, cf6_wind)
    if int(config['debug']) > 10:
        print('verification: found %d matching rows for wind' % count_rows)

    # Round values to nearest degree, knot, and centi-inch
    round_dict = {'wind_speed' : 0}
    if 'air_temp_high_6_hour' in vars_request:
        round_dict['air_temp_high_6_hour'] = 0
    if 'air_temp_low_6_hour' in vars_request:
        round_dict['air_temp_low_6_hour'] = 0
    round_dict['air_temp_max'] = 0
    round_dict['air_temp_min'] = 0
    if 'precip_accum_six_hour' in vars_request:
        round_dict['precip_accum_six_hour'] = 2
    round_dict['precip_accum_one_hour'] = 2
    obs_daily = obs_daily.round(round_dict)

    # Lastly, place all the values we found into a list of Daily objects.
    # Rename the columns and then iterate over rows.
    if 'air_temp_high_6_hour' in vars_request:
        obs_daily.rename(columns = {'air_temp_high_6_hour' : 'high'}, inplace=True)
    else:
        obs_daily.rename(columns = {'air_temp_max' : 'high'}, inplace=True)
    if 'air_temp_low_6_hour' in vars_request:
        obs_daily.rename(columns = {'air_temp_low_6_hour' : 'low'}, inplace=True)
    else:
        obs_daily.rename(columns = {'air_temp_min' : 'low'}, inplace=True)
    if 'precip_accum_six_hour' in vars_request:
        obs_daily.rename(columns = {'precip_accum_six_hour' : 'rain'}, inplace=True)
    else:
        obs_daily.rename(columns = {'precip_accum_one_hour' : 'rain'}, inplace=True)
    obs_daily.rename(columns = {'wind_speed' : 'wind'}, inplace=True)

    # Make sure rain has no missing values rather than zeros. Groupby
    # appropriately dealt with missing values earlier.
    obs_daily['rain'].fillna(0.0, inplace=True)
    # Set datetime as the index. This will help use datetime in the creation of
    # the Dailys.
    obs_daily = obs_daily.set_index(datename)
    # Remove extraneous columns
    export_cols = ['high', 'low', 'wind', 'rain']
    for col in obs_daily.columns:
        if col not in export_cols:
            obs_daily.drop(col, axis=1, inplace=True)

    # Create list of Daily objects
    dailys = []
    for index, row in obs_daily.iterrows():
        date = index.to_pydatetime()
        daily = Daily(stid, date)
        for attr in export_cols:
            setattr(daily, attr, row[attr])
        dailys.append(daily)

    return dailys

def main(config, stid):
    '''
    Retrieves yesterday and today's verification.

    We need to be careful about what the starting date is. If it is an
    incomplete verification day, then that inclomplete data will overwrite the
    previous day's verification. It is important, however, to make sure that
    we get the final values for yesterday. Therefore, let's make sure it
    starts at 6Z yesterday.
    '''
    
    end_date = datetime.utcnow()
    yesterday = end_date - timedelta(hours=24)
    start_date = datetime(yesterday.year, yesterday.month, yesterday.day, 6)
    start, end = _meso_api_dates(start_date, end_date)

    dailys = get_verification(config, stid, start, end)

    return dailys

def historical(config, stid, start_date):
    '''
    Retrieves historical verifications starting at start (datetime). Sets the
    hour of start to 6, so that we don't get incomplete verifications.
    '''
    
    start_date = start_date.replace(hour=6)
    end_date = datetime.utcnow()
    start, end = _meso_api_dates(start_date, end_date)
    
    dailys = get_verification(config, stid, start, end)
    
    return dailys



